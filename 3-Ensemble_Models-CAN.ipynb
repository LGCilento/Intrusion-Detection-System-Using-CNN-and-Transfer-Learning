{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly4ghmCk0cU0"
      },
      "source": [
        "# CHAPTER 3: A Transfer Learning and Optimized CNN Based Intrusion Detection System for Internet of Vehicles \n",
        "This is the code for the paper entitled \"**A Transfer Learning and Optimized CNN Based Intrusion Detection System for Internet of Vehicles**\" accepted in IEEE International Conference on Communications (IEEE ICC).  \n",
        "Authors: Li Yang (lyang339@uwo.ca) and Abdallah Shami (Abdallah.Shami@uwo.ca)  \n",
        "Organization: The Optimized Computing and Communications (OC2) Lab, ECE Department, Western University\n",
        "\n",
        "**Notebook 3: Ensemble Models**  \n",
        "Aims:  construct three ensemble techniques: Bagging, Probability averaging, and Concatenation, to further improve prediction accuracy  \n",
        "* Bagging: use majority voting of top single models  \n",
        "* Probability averaging: calculate the average probability of the single model prediction results (the last layer of CNN models), and select the largest probability class to be the final class  \n",
        "* Concatenation: extract the features in the last several layers of single models, and concatenate together to generate the new layers, and add a dense layer to do prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJDM8t-K0cU5"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Mx8KvwF0cU6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import keras\n",
        "from keras.models import Model,load_model\n",
        "from keras import Input\n",
        "from keras.layers import concatenate,Dense,Flatten,Dropout\n",
        "from keras.preprocessing.image import  ImageDataGenerator\n",
        "import keras.callbacks as kcallbacks\n",
        "import os\n",
        "import math\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.optimizers import gradient_descent_v2 #from keras.optimizers import SGD\n",
        "import operator\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN6cdfW40cU8"
      },
      "source": [
        "## Read the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp3eH6Bh0cU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ab4796-e61d-44a4-f39f-e5969ed103e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 116919 images belonging to 5 classes.\n",
            "CPU times: user 2.94 s, sys: 961 ms, total: 3.91 s\n",
            "Wall time: 3.09 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#generate images from train set and validation set\n",
        "TARGET_SIZE=(224,224)\n",
        "INPUT_SIZE=(224,224,3)\n",
        "BATCHSIZE=128\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        './data/test_224/',\n",
        "        target_size=TARGET_SIZE,\n",
        "        batch_size=BATCHSIZE,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLHdF-B00cU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e3fa3a-8a8c-47c7-9725-1e0cac17729d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
            "Wall time: 11 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#generate labels indicating disease (1) or normal (0)\n",
        "label=validation_generator.class_indices\n",
        "label={v: k for k, v in label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i058nn6M0cU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f604800c-7ceb-45c4-fb02-384a33280550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4'}\n"
          ]
        }
      ],
      "source": [
        "print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErPbRu0I0cU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d6368c-8f4b-431e-abea-a98e41c7f089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 ./data/test_224/3/458219.png\n",
            "CPU times: user 326 ms, sys: 42.4 ms, total: 369 ms\n",
            "Wall time: 365 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#read images from validation folder\n",
        "rootdir = './data/test_224/'\n",
        "test_laels = []\n",
        "test_images=[]\n",
        "for subdir, dirs, files in os.walk(rootdir):\n",
        "    for file in files:\n",
        "        if not (file.endswith(\".jpeg\"))|(file.endswith(\".jpg\"))|(file.endswith(\".png\")):\n",
        "            continue\n",
        "        test_laels.append(subdir.split('/')[-1])\n",
        "        test_images.append(os.path.join(subdir, file))\n",
        "        \n",
        "print(test_laels[0],test_images[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eETDhmZd0cVA"
      },
      "source": [
        "## Load 5 trained CNN models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWRiMTxu0cVA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c254e00a-4b62-40ff-865f-4c51b44a1c7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.31 s, sys: 214 ms, total: 1.53 s\n",
            "Wall time: 1.86 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        " #load model 1: xception\n",
        "xception_model=load_model('./xception.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bOUBHb8-0cVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce8baba-79bc-4641-cc70-759215abd45d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 445 ms, sys: 110 ms, total: 555 ms\n",
            "Wall time: 717 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        " #load model 2: VGG16\n",
        "vgg_model=load_model('./VGG16.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "T7KN4amD0cVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5ad6a2-ded1-41f2-ab06-d423fb127434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 427 ms, sys: 99.4 ms, total: 526 ms\n",
            "Wall time: 707 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        " #load model 3: VGG19\n",
        "vgg19_model=load_model('./VGG19.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Vx0ykdkJ0cVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "233f164b-78f8-4e2b-b4f6-d07d4b90b2e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.05 s, sys: 417 ms, total: 3.47 s\n",
            "Wall time: 3.94 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        " #load model 4: inception\n",
        "incep_model=load_model('./inception.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "B0epREyH0cVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf36117-7ba2-4c09-afef-1558e5278a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.12 s, sys: 785 ms, total: 7.9 s\n",
            "Wall time: 7.73 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        " #load model 5: inceptionresnet\n",
        "inres_model=load_model('./inceptionresnet.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm5KCYrb0cVC"
      },
      "source": [
        "## Use the original CNN base models to make predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSHpbhBX0cVC"
      },
      "source": [
        "### 1. Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwy0QSaX0cVD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "ab552dea-1268-46f2-cdc1-079658bbee07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted result for the first image: 3\n",
            "Confidence level: 0.99999917\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.16 s, sys: 30.8 ms, total: 1.19 s\n",
            "Wall time: 1.47 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#Single image prediction\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "test=cv2.imread(test_images[0])\n",
        "\n",
        "img_show=test[:,:,[2,1,0]]\n",
        "test=test/255.\n",
        "test_shape=(1,)+test.shape\n",
        "test=test.reshape(test_shape)\n",
        "\n",
        "res=xception_model.predict(test)\n",
        "\n",
        "prob=res[0,np.argmax(res,axis=1)[0]]\n",
        "res=label[np.argmax(res,axis=1)[0]]\n",
        "print('Predicted result for the first image: %s'%res)\n",
        "print('Confidence level: %s'%prob)\n",
        "plt.imshow(img_show)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjzRDlj-0cVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2eb000f-25d2-408b-f213-a7fce0a316d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1h 52min 10s, sys: 6min 4s, total: 1h 58min 14s\n",
            "Wall time: 1h 54min 15s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import time\n",
        "predict=[]\n",
        "length=len(test_images)\n",
        "t1 = time.time()\n",
        "for i in range(length):\n",
        "    inputimg=test_images[i]\n",
        "    test_batch=[]\n",
        "    thisimg=np.array(Image.open(inputimg))/255 #read all the images in validation set\n",
        "    #print(thisimg)\n",
        "    test_shape=(1,)+thisimg.shape\n",
        "    thisimg=thisimg.reshape(test_shape)\n",
        "    xception_model_batch=xception_model.predict(thisimg) #use master model to process the input image\n",
        "    #generate result by model 1\n",
        "    prob=xception_model_batch[0,np.argmax(xception_model_batch,axis=1)[0]]\n",
        "    res=label[np.argmax(xception_model_batch,axis=1)[0]]\n",
        "    predict.append(res)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cM4Yrbo50cVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e70664e-780e-4e41-873d-e1f2c3d91fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xception accuracy: 1.0\n",
            "precision: 1.0\n",
            "recall: 1.0\n",
            "f1: 1.0\n",
            "[[100166      0      0      0      0]\n",
            " [     0   4630      0      0      0]\n",
            " [     0      0   4322      0      0]\n",
            " [     0      0      0   4186      0]\n",
            " [     0      0      0      0   3615]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    100166\n",
            "           1       1.00      1.00      1.00      4630\n",
            "           2       1.00      1.00      1.00      4322\n",
            "           3       1.00      1.00      1.00      4186\n",
            "           4       1.00      1.00      1.00      3615\n",
            "\n",
            "    accuracy                           1.00    116919\n",
            "   macro avg       1.00      1.00      1.00    116919\n",
            "weighted avg       1.00      1.00      1.00    116919\n",
            "\n",
            "CPU times: user 2.05 s, sys: 6.99 ms, total: 2.06 s\n",
            "Wall time: 2.04 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "acc=accuracy_score(test_laels,predict)\n",
        "pre=precision_score(test_laels,predict,average='weighted')\n",
        "re=recall_score(test_laels,predict,average='weighted')\n",
        "f1=f1_score(test_laels,predict,average='weighted')\n",
        "print('Xception accuracy: %s'%acc)\n",
        "print('precision: %s'%pre)\n",
        "print('recall: %s'%re)\n",
        "print('f1: %s'%f1)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(test_laels, predict))\n",
        "target_names = ['0', '1','2','3','4']\n",
        "print(classification_report(test_laels, predict, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsdbGjIz0cVE"
      },
      "source": [
        "### 2. VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN_uIIo10cVE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "5c431f4a-a89a-43c4-a2e8-7d4bcc634716"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-1d93885b3c12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict=[]\\nlength=len(test_images)\\nt1 = time.time()\\nfor i in range(length):\\n    inputimg=test_images[i]\\n    test_batch=[]\\n    thisimg=np.array(Image.open(inputimg))/255 #read all the images in validation set\\n    #print(thisimg)\\n    test_shape=(1,)+thisimg.shape\\n    thisimg=thisimg.reshape(test_shape)\\n    vgg_model_batch=vgg_model.predict(thisimg) #use master model to process the input image\\n    #generate result by model 1\\n    prob=vgg_model_batch[0,np.argmax(vgg_model_batch,axis=1)[0]]\\n    res=label[np.argmax(vgg_model_batch,axis=1)[0]]\\n    predict.append(res)\\n    '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1975\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1976\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;31m# initialize the variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m       \u001b[0mvalue_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1702\u001b[0m           \u001b[0;34m\"%sConversion function %r for type %s returned non-Tensor: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m           (_error_prefix(name), conversion_func, base_type, ret))\n\u001b[0;32m-> 1704\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m       raise RuntimeError(\n\u001b[1;32m   1706\u001b[0m           \u001b[0;34m\"%sConversion function %r for type %s returned incompatible \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     \u001b[0;31m# Note: using the intern table directly here as this is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;31m# performance-sensitive in some models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_INTERN_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datatype_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%%time\n",
        "predict=[]\n",
        "length=len(test_images)\n",
        "t1 = time.time()\n",
        "for i in range(length):\n",
        "    inputimg=test_images[i]\n",
        "    test_batch=[]\n",
        "    thisimg=np.array(Image.open(inputimg))/255 #read all the images in validation set\n",
        "    #print(thisimg)\n",
        "    test_shape=(1,)+thisimg.shape\n",
        "    thisimg=thisimg.reshape(test_shape)\n",
        "    vgg_model_batch=vgg_model.predict(thisimg) #use master model to process the input image\n",
        "    #generate result by model 1\n",
        "    prob=vgg_model_batch[0,np.argmax(vgg_model_batch,axis=1)[0]]\n",
        "    res=label[np.argmax(vgg_model_batch,axis=1)[0]]\n",
        "    predict.append(res)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPSzakTD0cVE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "acc=accuracy_score(test_laels,predict)\n",
        "pre=precision_score(test_laels,predict,average='weighted')\n",
        "re=recall_score(test_laels,predict,average='weighted')\n",
        "f1=f1_score(test_laels,predict,average='weighted')\n",
        "print('VGG16 accuracy: %s'%acc)\n",
        "print('precision: %s'%pre)\n",
        "print('recall: %s'%re)\n",
        "print('f1: %s'%f1)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(test_laels, predict))\n",
        "target_names = ['0', '1','2','3','4']\n",
        "print(classification_report(test_laels, predict, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ1Hl0IF0cVF"
      },
      "source": [
        "### 3. VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9JBnlDM0cVF"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "predict=[]\n",
        "length=len(test_images)\n",
        "t1 = time.time()\n",
        "for i in range(length):\n",
        "    inputimg=test_images[i]\n",
        "    test_batch=[]\n",
        "    thisimg=np.array(Image.open(inputimg))/255 #read all the images in validation set\n",
        "    #print(thisimg)\n",
        "    test_shape=(1,)+thisimg.shape\n",
        "    thisimg=thisimg.reshape(test_shape)\n",
        "    vgg19_model_batch=vgg19_model.predict(thisimg) #use master model to process the input image\n",
        "    #generate result by model 1\n",
        "    prob=vgg19_model_batch[0,np.argmax(vgg19_model_batch,axis=1)[0]]\n",
        "    res=label[np.argmax(vgg19_model_batch,axis=1)[0]]\n",
        "    predict.append(res)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH6psuk_0cVF"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "acc=accuracy_score(test_laels,predict)\n",
        "pre=precision_score(test_laels,predict,average='weighted')\n",
        "re=recall_score(test_laels,predict,average='weighted')\n",
        "f1=f1_score(test_laels,predict,average='weighted')\n",
        "print('VGG19 accuracy: %s'%acc)\n",
        "print('precision: %s'%pre)\n",
        "print('recall: %s'%re)\n",
        "print('f1: %s'%f1)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(test_laels, predict))\n",
        "target_names = ['0', '1','2','3','4']\n",
        "print(classification_report(test_laels, predict, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF-fMQm80cVF"
      },
      "source": [
        "### 4. Inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diIxNH070cVG"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "predict=[]\n",
        "length=len(test_images)\n",
        "t1 = time.time()\n",
        "for i in range(length):\n",
        "    inputimg=test_images[i]\n",
        "    test_batch=[]\n",
        "    thisimg=np.array(Image.open(inputimg))/255 #read all the images in validation set\n",
        "    #print(thisimg)\n",
        "    test_shape=(1,)+thisimg.shape\n",
        "    thisimg=thisimg.reshape(test_shape)\n",
        "    incep_model_batch=incep_model.predict(thisimg) #use master model to process the input image\n",
        "    #generate result by model 1\n",
        "    prob=incep_model_batch[0,np.argmax(incep_model_batch,axis=1)[0]]\n",
        "    res=label[np.argmax(incep_model_batch,axis=1)[0]]\n",
        "    predict.append(res)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MKSyeG30cVG"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "acc=accuracy_score(test_laels,predict)\n",
        "pre=precision_score(test_laels,predict,average='weighted')\n",
        "re=recall_score(test_laels,predict,average='weighted')\n",
        "f1=f1_score(test_laels,predict,average='weighted')\n",
        "print('inception accuracy: %s'%acc)\n",
        "print('precision: %s'%pre)\n",
        "print('recall: %s'%re)\n",
        "print('f1: %s'%f1)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(test_laels, predict))\n",
        "target_names = ['0', '1','2','3','4']\n",
        "print(classification_report(test_laels, predict, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeIWC_LZ0cVG"
      },
      "source": [
        "### 5. InceptionResnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oG_nliX0cVG"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "predict=[]\n",
        "length=len(test_images)\n",
        "t1 = time.time()\n",
        "for i in range(length):\n",
        "    inputimg=test_images[i]\n",
        "    test_batch=[]\n",
        "    thisimg=np.array(Image.open(inputimg))/255 #read all the images in validation set\n",
        "    #print(thisimg)\n",
        "    test_shape=(1,)+thisimg.shape\n",
        "    thisimg=thisimg.reshape(test_shape)\n",
        "    inres_model_batch=inres_model.predict(thisimg) #use master model to process the input image\n",
        "    #generate result by model 1\n",
        "    prob=inres_model_batch[0,np.argmax(inres_model_batch,axis=1)[0]]\n",
        "    res=label[np.argmax(inres_model_batch,axis=1)[0]]\n",
        "    predict.append(res)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H4x_VRg0cVG"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "acc=accuracy_score(test_laels,predict)\n",
        "pre=precision_score(test_laels,predict,average='weighted')\n",
        "re=recall_score(test_laels,predict,average='weighted')\n",
        "f1=f1_score(test_laels,predict,average='weighted')\n",
        "print('inceptionresnet accuracy: %s'%acc)\n",
        "print('precision: %s'%pre)\n",
        "print('recall: %s'%re)\n",
        "print('f1: %s'%f1)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(test_laels, predict))\n",
        "target_names = ['0', '1','2','3','4']\n",
        "print(classification_report(test_laels, predict, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Amk6hSKE0cVH"
      },
      "source": [
        "### 6. Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tV_QTsh00cVH"
      },
      "outputs": [],
      "source": [
        " #load model 6: resnet\n",
        "res_model=load_model('./resnet.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Giyd98C30cVH"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "predict=[]\n",
        "length=len(test_images)\n",
        "t1 = time.time()\n",
        "for i in range(length):\n",
        "    inputimg=test_images[i]\n",
        "    test_batch=[]\n",
        "    thisimg=np.array(Image.open(inputimg))/255 #read all the images in validation set\n",
        "    #print(thisimg)\n",
        "    test_shape=(1,)+thisimg.shape\n",
        "    thisimg=thisimg.reshape(test_shape)\n",
        "    res_model_batch=res_model.predict(thisimg) #use master model to process the input image\n",
        "    #generate result by model 1\n",
        "    prob=res_model_batch[0,np.argmax(res_model_batch,axis=1)[0]]\n",
        "    res=label[np.argmax(res_model_batch,axis=1)[0]]\n",
        "    predict.append(res)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huuXppTd0cVH"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "acc=accuracy_score(test_laels,predict)\n",
        "pre=precision_score(test_laels,predict,average='weighted')\n",
        "re=recall_score(test_laels,predict,average='weighted')\n",
        "f1=f1_score(test_laels,predict,average='weighted')\n",
        "print('resnet accuracy: %s'%acc)\n",
        "print('precision: %s'%pre)\n",
        "print('recall: %s'%re)\n",
        "print('f1: %s'%f1)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(test_laels, predict))\n",
        "target_names = ['0', '1','2','3','4']\n",
        "print(classification_report(test_laels, predict, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCWzFnBY0cVH"
      },
      "source": [
        "Best performing single model (vgg):  \n",
        "Accuracy: 99.96"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTrtxIRc0cVH"
      },
      "source": [
        "# Bagging ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEy8USIO0cVI"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "import time\n",
        "predict=[]\n",
        "length=len(test_images)\n",
        "t1 = time.time()\n",
        "for i in range((length//127)+1):\n",
        "    inputimg=test_images[127*i:127*(i+1)]\n",
        "    test_batch=[]\n",
        "    for path in inputimg:\n",
        "        thisimg=np.array(Image.open(path))/255\n",
        "        test_batch.append(thisimg)\n",
        "    #generate result by model 1\n",
        "    xception_model_batch=xception_model.predict(np.array(test_batch))\n",
        "    xception_model_batch=list(np.argmax(xception_model_batch,axis=1))\n",
        "    xception_model_batch=[label[con] for con in xception_model_batch]\n",
        "#     print(xception_model_batch)\n",
        "    #generate result by model 2\n",
        "    vgg_model_batch=vgg_model.predict(np.array(test_batch))\n",
        "    vgg_model_batch=list(np.argmax(vgg_model_batch,axis=1))\n",
        "    vgg_model_batch=[label[con] for con in vgg_model_batch]\n",
        "#     print(vgg_model_batch)\n",
        "    #generate result by model 3\n",
        "    vgg19_model_batch=vgg19_model.predict(np.array(test_batch))\n",
        "    vgg19_model_batch=list(np.argmax(vgg19_model_batch,axis=1))\n",
        "    vgg19_model_batch=[label[con] for con in vgg19_model_batch]\n",
        "#     print(vgg19_model_batch)\n",
        "    #generate result by model 4\n",
        "    incep_model_batch=incep_model.predict(np.array(test_batch))\n",
        "    incep_model_batch=list(np.argmax(incep_model_batch,axis=1))\n",
        "    incep_model_batch=[label[con] for con in incep_model_batch]\n",
        "#     print(incep_model_batch)\n",
        "    #generate result by model 5\n",
        "    inres_model_batch=inres_model.predict(np.array(test_batch))\n",
        "    inres_model_batch=list(np.argmax(inres_model_batch,axis=1))\n",
        "    inres_model_batch=[label[con] for con in inres_model_batch]\n",
        "#     print(inres_model_batch)\n",
        "    #bagging the three results generated by 3 singular models\n",
        "    predict_batch=[]\n",
        "    for i,j,k,p,q in zip(xception_model_batch,vgg_model_batch,vgg19_model_batch,incep_model_batch,inres_model_batch):\n",
        "        count=defaultdict(int)\n",
        "        count[i]+=1\n",
        "        count[j]+=1\n",
        "        count[k]+=1\n",
        "        count[p]+=1\n",
        "        count[q]+=1\n",
        "        #rank the predicted results in descending order\n",
        "        predict_one=sorted(count.items(), key=operator.itemgetter(1),reverse=True)[0][0]\n",
        "        predict_batch.append(predict_one)\n",
        "#     print('predict:',predict_batch)\n",
        "    predict.append(predict_batch)\n",
        "t2 = time.time()\n",
        "print('The testing time is :%f seconds' % (t2-t1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hNyeyDlV0cVI"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "predict=sum(predict,[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igdtVpdm0cVI"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "acc=accuracy_score(test_laels,predict)\n",
        "print('bagging accuracy:%s'%acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvsDVxMg0cVI"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(test_laels, predict))\n",
        "target_names = ['0', '1','2','3','4']\n",
        "print(classification_report(test_laels, predict, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "dKI5L0xS0cVI"
      },
      "source": [
        "After bagging ensemble, the accuracy improved to 0.990"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "YtSZOKpC0cVJ"
      },
      "source": [
        "# Probability Averaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aXZGTan40cVJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Model,load_model\n",
        "from keras import Input\n",
        "from keras.layers import concatenate,Dense,Flatten,Dropout,Average\n",
        "from keras.preprocessing.image import  ImageDataGenerator\n",
        "import keras.callbacks as kcallbacks\n",
        "import os\n",
        "import math\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.optimizers import gradient_descent_v2 #from keras.optimizers import SGD\n",
        "import operator\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "import tensorflow as tf\n",
        "#tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0-yK4Ta0cVJ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "import time\n",
        "t1 = time.time()\n",
        "img=Input(shape=(224,224,3),name='img')\n",
        "feature1=xception_model(img)\n",
        "feature2=vgg_model(img)\n",
        "feature3=incep_model(img)\n",
        "for layer in xception_model.layers:  \n",
        "    layer.trainable = False \n",
        "for layer in vgg_model.layers:  \n",
        "    layer.trainable = False  \n",
        "for layer in incep_model.layers:  \n",
        "    layer.trainable = False  \n",
        "output=Average()([feature1,feature2,feature3]) #add the confidence lists generated by 3 models\n",
        "model=Model(inputs=img,outputs=output)\n",
        "\n",
        "#the optimization function\n",
        "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "t2 = time.time()\n",
        "print('The testing time is :%f seconds' % (t2-t1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7hX9zcJ0cVJ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#read images from validation folder\n",
        "rootdir = './data/test_224/'\n",
        "test_laels = []\n",
        "test_images=[]\n",
        "for subdir, dirs, files in os.walk(rootdir):\n",
        "    for file in files:\n",
        "        if not (file.endswith(\".jpeg\"))|(file.endswith(\".jpg\"))|(file.endswith(\".png\")):\n",
        "            continue\n",
        "        test_laels.append(subdir.split('/')[-1])\n",
        "        test_images.append(os.path.join(subdir, file))\n",
        "        \n",
        "print(test_laels[0],test_images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAPbb9Z50cVJ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#test the averaging model on the validation set\n",
        "import time\n",
        "predict=[]\n",
        "length=len(test_images)\n",
        "t1 = time.time()\n",
        "for i in range((length//127)+1):\n",
        "    inputimg=test_images[127*i:127*(i+1)]\n",
        "    test_batch=[]\n",
        "    for path in inputimg:\n",
        "        thisimg=np.array(Image.open(path))/255\n",
        "        test_batch.append(thisimg)\n",
        "    #print(i, np.array(test_batch).shape)\n",
        "    model_batch=model.predict(np.array(test_batch))\n",
        "    predict_batch=list(np.argmax(model_batch,axis=1))\n",
        "    predict_batch=[label[con] for con in predict_batch]\n",
        "    predict.append(predict_batch)\n",
        "\n",
        "predict=sum(predict,[])\n",
        "\n",
        "t2 = time.time()\n",
        "print('The testing time is :%f seconds' % (t2-t1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwD_dBAk0cVJ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc=accuracy_score(test_laels,predict)\n",
        "print('Probability Averaging accuracy:%s'%acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29UtX8No0cVK"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(test_laels, predict))\n",
        "target_names = ['0', '1','2','3','4']\n",
        "print(classification_report(test_laels, predict, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TClHmk3L0cVK"
      },
      "source": [
        "# Concatenation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHDTsH6l0cVK"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Model,load_model\n",
        "from keras import Input\n",
        "from keras.layers import concatenate,Dense,Flatten,Dropout\n",
        "from keras.preprocessing.image import  ImageDataGenerator\n",
        "import keras.callbacks as kcallbacks\n",
        "import os\n",
        "import math\n",
        "from keras.utils import plot_model\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.optimizers import gradient_descent_v2 #from keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIiPEpgD0cVK"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "for i,layer in enumerate(xception_model.layers):\n",
        "    print(i,layer.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNNFuP4t0cVK"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "for i,layer in enumerate(vgg_model.layers):\n",
        "    print(i,layer.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLcK1HH90cVK"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "for i,layer in enumerate(vgg19_model.layers):\n",
        "    print(i,layer.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9diyvZW0cVL"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "for i,layer in enumerate(incep_model.layers):\n",
        "    print(i,layer.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zfUcg6b0cVL"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "for i,layer in enumerate(inres_model.layers):\n",
        "    print(i,layer.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qduk_Rrn0cVL"
      },
      "source": [
        "### Construct the ensemble model using the last \"dense layer\" of each base CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb_Wjn_u0cVL"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model1=Model(inputs=[xception_model.layers[0].get_input_at(0)],outputs=xception_model.get_layer('dense_6').output,name='xception')\n",
        "model2=Model(inputs=[vgg_model.layers[0].get_input_at(0)],outputs=vgg_model.get_layer('dense_8').output,name='vgg')\n",
        "model3=Model(inputs=[vgg19_model.layers[0].get_input_at(0)],outputs=vgg19_model.get_layer('dense_10').output,name='vgg19')\n",
        "model4=Model(inputs=[incep_model.layers[0].get_input_at(0)],outputs=incep_model.get_layer('dense_14').output,name='incep')\n",
        "model5=Model(inputs=[inres_model.layers[0].get_input_at(0)],outputs=inres_model.get_layer('dense_16').output,name='inres')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ng2fAIil0cVL"
      },
      "outputs": [],
      "source": [
        "#plot the figures\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = {'batch':[], 'epoch':[]}\n",
        "        self.accuracy = {'batch':[], 'epoch':[]}\n",
        "        self.val_loss = {'batch':[], 'epoch':[]}\n",
        "        self.val_accuracy = {'batch':[], 'epoch':[]}\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses['batch'].append(logs.get('loss'))\n",
        "        self.accuracy['batch'].append(logs.get('acc'))\n",
        "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
        "        self.val_accuracy['batch'].append(logs.get('val_accuracy'))\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.losses['epoch'].append(logs.get('loss'))\n",
        "        self.accuracy['epoch'].append(logs.get('acc'))\n",
        "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
        "        self.val_accuracy['epoch'].append(logs.get('val_accuracy'))\n",
        "    def loss_plot(self, loss_type):\n",
        "        iters = range(len(self.losses[loss_type]))\n",
        "        plt.figure()\n",
        "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
        "        if loss_type == 'epoch':\n",
        "            # acc\n",
        "            plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
        "            # loss\n",
        "            plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
        "            # val_acc\n",
        "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
        "            # val_loss\n",
        "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
        "        plt.grid(True)\n",
        "        plt.xlabel(loss_type)\n",
        "        plt.ylabel('acc-loss')\n",
        "        plt.legend(loc=\"upper right\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZxEk9aO50cVL"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "ensemble_history= LossHistory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KckCtcWj0cVL"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#generate training and test images\n",
        "TARGET_SIZE=(224,224)\n",
        "INPUT_SIZE=(224,224,3)\n",
        "BATCHSIZE=128\t#could try 128 or 32\n",
        "\n",
        "#Normalization\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        './train_224/',\n",
        "        target_size=TARGET_SIZE,\n",
        "        batch_size=BATCHSIZE,\n",
        "        class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        './test_224/',\n",
        "        target_size=TARGET_SIZE,\n",
        "        batch_size=BATCHSIZE,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mm31Br6a0cVM"
      },
      "outputs": [],
      "source": [
        "def lr_decay(epoch):\n",
        "    lrs = [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001,0.00001,0.000001,\n",
        "           0.000001,0.000001,0.000001,0.000001,0.0000001,0.0000001,0.0000001,0.0000001,0.0000001,0.0000001\n",
        "          ]\n",
        "    return lrs[epoch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nMKFDK_P0cVM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "auto_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
        "my_lr = LearningRateScheduler(lr_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5lpqbm10cVM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "def ensemble(num_class,epochs,savepath='./ensemble.h5'):\n",
        "    img=Input(shape=(224,224,3),name='img')\n",
        "    feature1=model1(img)\n",
        "    feature2=model2(img)\n",
        "    feature3=model3(img)\n",
        "    x=concatenate([feature1,feature2,feature3])\n",
        "    x=Dropout(0.5)(x)\n",
        "    x=Dense(64,activation='relu')(x)\n",
        "    x=Dropout(0.25)(x)\n",
        "    output=Dense(num_class,activation='softmax',name='output')(x)\n",
        "    model=Model(inputs=img,outputs=output)\n",
        "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    #train model\n",
        "    earlyStopping=kcallbacks.EarlyStopping(monitor='val_accuracy',patience=2, verbose=1, mode='auto')\n",
        "    saveBestModel = kcallbacks.ModelCheckpoint(filepath=savepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')\n",
        "    hist=model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(train_generator),\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=len(validation_generator),\n",
        "        callbacks=[earlyStopping,saveBestModel,ensemble_history,auto_lr],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6qSVvZ00cVM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "ensemble_model=ensemble(num_class=5,epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6h2Fd7PN0cVM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "ensemble_model=load_model('./ensemble.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mhcfb86v0cVM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#read images from validation folder\n",
        "rootdir = './data/test_224/'\n",
        "test_laels = []\n",
        "test_images=[]\n",
        "for subdir, dirs, files in os.walk(rootdir):\n",
        "    for file in files:\n",
        "        if not (file.endswith(\".jpeg\"))|(file.endswith(\".jpg\"))|(file.endswith(\".png\")):\n",
        "            continue\n",
        "        test_laels.append(subdir.split('/')[-1])\n",
        "        test_images.append(os.path.join(subdir, file))\n",
        "        \n",
        "print(test_laels[0],test_images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2dEzzJC0cVN"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#test the averaging model on the validation set\n",
        "import time\n",
        "predict=[]\n",
        "length=len(test_images)\n",
        "t1 = time.time()\n",
        "for i in range((length//127)+1):\n",
        "    inputimg=test_images[127*i:127*(i+1)]\n",
        "    test_batch=[]\n",
        "    for path in inputimg:\n",
        "        thisimg=np.array(Image.open(path))/255\n",
        "        test_batch.append(thisimg)\n",
        "    #print(i, np.array(test_batch).shape)\n",
        "    ensemble_model_batch=ensemble_model.predict(np.array(test_batch))\n",
        "    predict_batch=list(np.argmax(ensemble_model_batch,axis=1))\n",
        "    predict_batch=[label[con] for con in predict_batch]\n",
        "    predict.append(predict_batch)\n",
        "\n",
        "predict=sum(predict,[])\n",
        "\n",
        "t2 = time.time()\n",
        "print('The testing time is :%f seconds' % (t2-t1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntQ9F4Sl0cVN"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "acc=accuracy_score(test_laels,predict)\n",
        "print('Concatenation accuracy:%s'%acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oKX5MJ20cVN"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(test_laels, predict))\n",
        "target_names = ['0', '1','2','3','4']\n",
        "print(classification_report(test_laels, predict, target_names=target_names))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "tf36cnn",
      "language": "python",
      "name": "tf36cnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "3-Ensemble_Models-CAN.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}